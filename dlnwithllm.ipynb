{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50d50964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cd148",
   "metadata": {},
   "source": [
    "### Data Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f222ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_thuong_tru_filtered.csv')\n",
    "df[\"question_note\"] = df[\"question_note\"].fillna(df[\"question_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc68ec4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Action                                      question_text  \\\n",
      "10     NaN  Trực tiếp đăng ký thường trú tại nhà mình đang...   \n",
      "11     NaN  Trực tiếp đăng ký thường trú tại nhà mình đang...   \n",
      "12     NaN  Việc lưu trữ hồ sơ đăng ký thường trú được thự...   \n",
      "95     NaN  Người Việt Nam định cư ở nước ngoài về Việt Na...   \n",
      "103    NaN  Công dân Việt Nam thường trú ở nước ngoài là g...   \n",
      "124    NaN      Người nước ngoài thường trú ở Việt Nam là gì?   \n",
      "170    NaN  Xin cho biết về thủ tục xin thường trú và cơ q...   \n",
      "212    NaN  Như thế nào là cư trú, thường trú, tạm trú, lư...   \n",
      "219    NaN  Tôi có hộ khẩu thường trú tại tỉnh Hà Nam và h...   \n",
      "227    NaN  Lệ phí đăng ký cư trú sẽ được thống nhất trên ...   \n",
      "243    NaN  Cư trú, nơi thường trú theo quy định hiện nay ...   \n",
      "322    NaN  Theo quy định thì nơi thường trú được hiểu như...   \n",
      "445    NaN  Thế nào là thườngtrú, lưutrúvàtạm trú? Thườngt...   \n",
      "\n",
      "                                         question_note  \n",
      "10    Tôi tên Hồng năm nay 45 tuổi tôi ở Nghệ An gi...  \n",
      "11   Tôi tên Hồng năm nay 45 tuổi tôi ở Nghệ An giờ...  \n",
      "12   Việc lưu trữ hồ sơ đăng ký thường trú được thự...  \n",
      "95   Người Việt Nam định cư ở nước ngoài về Việt Na...  \n",
      "103  Công dân Việt Nam thường trú ở nước ngoài là g...  \n",
      "124      Người nước ngoài thường trú ở Việt Nam là gì?  \n",
      "170   Nhờ luật sư giải đáp về nghĩa vụ và quyền lợi...  \n",
      "212                         Như thế nào là thường trú?  \n",
      "219  Tôi có hộ khẩu thường trú tại tỉnh Hà Nam và h...  \n",
      "227  Lệ phí đăng ký cư trú sẽ được thống nhất trên ...  \n",
      "243  , nơi thường trú theo quy định hiện nay được h...  \n",
      "322  Theo quy định thì nơi thường trú được hiểu như...  \n",
      "445                             Thế nào là thườngtrú,   \n"
     ]
    }
   ],
   "source": [
    "null_action_rows = df[df['Action'].isnull()]\n",
    "print(null_action_rows[['Action', 'question_text', 'question_note', ]])\n",
    "df = df.dropna(subset=['Action'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f83ded26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action\n",
      "Đăng ký thường trú                 308\n",
      "Xóa đăng ký thường trú              81\n",
      "Cấp thẻ thường trú                  39\n",
      "Điều chỉnh thông tin thường trú      5\n",
      "Chuyển đăng ký                       2\n",
      "Gia hạn                              2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['Action'] == 'Điều chỉnh', 'Action'] = 'Điều chỉnh thông tin thường trú'\n",
    "df.loc[df['Action'] == 'Đăng ký/Khai báo', 'Action'] = 'Đăng ký thường trú'\n",
    "df.loc[df['Action'] == 'Xóa', 'Action'] = 'Xóa đăng ký thường trú'\n",
    "count = df['Action'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76ef787b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_note</th>\n",
       "      <th>question_type</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Type</th>\n",
       "      <th>Action</th>\n",
       "      <th>related_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chào anh chị, cho em hỏi em có hộ khẩu thường ...</td>\n",
       "      <td>Yes/No</td>\n",
       "      <td>VN_lớn_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Xóa đăng ký thường trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thủ tục đăng ký thường trú được quy định như t...</td>\n",
       "      <td>What</td>\n",
       "      <td>VN_lớn_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hồ sơ, thủ tục xóa đăng ký thường trú quy địn...</td>\n",
       "      <td>What</td>\n",
       "      <td>VN_lớn_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Xóa đăng ký thường trú</td>\n",
       "      <td>Người lao động</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tôi muốn đăng ký cư trú thì những loại giấy tờ...</td>\n",
       "      <td>What</td>\n",
       "      <td>VN_lớn_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Đăng ký cư trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cho hỏi mức lệ phí đăng ký thường trú, đăng ký...</td>\n",
       "      <td>What</td>\n",
       "      <td>VN_lớn_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>Xin chào Ban biên tập, tôi là Minh Ngọc hiện đ...</td>\n",
       "      <td>Which</td>\n",
       "      <td>NN</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Nơi cư trú của công dân</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>Mẫu phiếu từ chối tiếp nhận hồ soe hồ sơ  cư trú</td>\n",
       "      <td>What</td>\n",
       "      <td>VN_bé_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Xóa đăng ký thường trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>Thẻtạm trúcủa phóng viên nước ngoài thườngtrút...</td>\n",
       "      <td>How</td>\n",
       "      <td>NN</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Thẻ tạm trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>Tôi có một câu hỏi liên quan đến việc cấp đổi ...</td>\n",
       "      <td>What</td>\n",
       "      <td>NN</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Thẻ thường trú</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>Những người ở cùng một chỗ ở hợp pháp có quan ...</td>\n",
       "      <td>How</td>\n",
       "      <td>VN_lớn_hơn_14</td>\n",
       "      <td>Thường_trú</td>\n",
       "      <td>Đăng ký thường trú</td>\n",
       "      <td>Chỗ ở hợp pháp; Đăng ký thường trú</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>437 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         question_note question_type  \\\n",
       "0    Chào anh chị, cho em hỏi em có hộ khẩu thường ...        Yes/No   \n",
       "1    Thủ tục đăng ký thường trú được quy định như t...          What   \n",
       "2     Hồ sơ, thủ tục xóa đăng ký thường trú quy địn...          What   \n",
       "3    Tôi muốn đăng ký cư trú thì những loại giấy tờ...          What   \n",
       "4    Cho hỏi mức lệ phí đăng ký thường trú, đăng ký...          What   \n",
       "..                                                 ...           ...   \n",
       "444  Xin chào Ban biên tập, tôi là Minh Ngọc hiện đ...         Which   \n",
       "446   Mẫu phiếu từ chối tiếp nhận hồ soe hồ sơ  cư trú          What   \n",
       "447  Thẻtạm trúcủa phóng viên nước ngoài thườngtrút...           How   \n",
       "448  Tôi có một câu hỏi liên quan đến việc cấp đổi ...          What   \n",
       "449  Những người ở cùng một chỗ ở hợp pháp có quan ...           How   \n",
       "\n",
       "           Subject        Type                  Action  \\\n",
       "0    VN_lớn_hơn_14  Thường_trú  Xóa đăng ký thường trú   \n",
       "1    VN_lớn_hơn_14  Thường_trú      Đăng ký thường trú   \n",
       "2    VN_lớn_hơn_14  Thường_trú  Xóa đăng ký thường trú   \n",
       "3    VN_lớn_hơn_14  Thường_trú      Đăng ký thường trú   \n",
       "4    VN_lớn_hơn_14  Thường_trú      Đăng ký thường trú   \n",
       "..             ...         ...                     ...   \n",
       "444             NN  Thường_trú      Đăng ký thường trú   \n",
       "446   VN_bé_hơn_14  Thường_trú  Xóa đăng ký thường trú   \n",
       "447             NN  Thường_trú      Đăng ký thường trú   \n",
       "448             NN  Thường_trú      Đăng ký thường trú   \n",
       "449  VN_lớn_hơn_14  Thường_trú      Đăng ký thường trú   \n",
       "\n",
       "                           related_tags  \n",
       "0                    Đăng ký thường trú  \n",
       "1                    Đăng ký thường trú  \n",
       "2                        Người lao động  \n",
       "3                        Đăng ký cư trú  \n",
       "4                    Đăng ký thường trú  \n",
       "..                                  ...  \n",
       "444             Nơi cư trú của công dân  \n",
       "446                  Đăng ký thường trú  \n",
       "447                         Thẻ tạm trú  \n",
       "448                      Thẻ thường trú  \n",
       "449  Chỗ ở hợp pháp; Đăng ký thường trú  \n",
       "\n",
       "[437 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df\n",
    "df_cleaned.drop('Liên quan?', axis=1, inplace=True)\n",
    "df_cleaned.drop('label', axis=1, inplace=True)\n",
    "df_cleaned.drop('Circumstance', axis=1, inplace=True)\n",
    "df_cleaned.drop('detail_url', axis=1, inplace=True)\n",
    "df_cleaned.drop('answer', axis=1, inplace=True)\n",
    "df_cleaned.drop('answer_level', axis=1, inplace=True)\n",
    "df_cleaned.drop('note_answer', axis=1, inplace=True)\n",
    "df_cleaned.drop('key_answer', axis=1, inplace=True)\n",
    "df_cleaned.drop('laws', axis=1, inplace=True)\n",
    "df_cleaned.drop('question_text', axis=1, inplace=True)\n",
    "df_cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2973c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    chào anh chị, cho em hỏi em có hộ khẩu thường ...\n",
      "1    thủ tục đăng ký thường trú được quy định như t...\n",
      "2    hồ sơ, thủ tục xóa đăng ký thường trú quy định...\n",
      "3    tôi muốn đăng ký cư trú thì những loại giấy tờ...\n",
      "4    cho hỏi mức lệ phí đăng ký thường trú, đăng ký...\n",
      "Name: question_note, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)  # Remove HTML tags\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', ' ', text, flags=re.MULTILINE)  # Remove URLs\n",
    "    text = re.sub(r'\\S+@\\S+', ' ', text)  # Remove email addresses\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?()-]', '', text)  # Remove special characters except punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text) # Remove extra spaces\n",
    "    return text.strip()  # Thêm dòng này để trả về kết quả\n",
    "\n",
    "df['question_note'] = df['question_note'].apply(clean_text)\n",
    "df['Subject'] = df['Subject'].apply(clean_text)\n",
    "df['Type'] = df['Type'].apply(clean_text)\n",
    "df['related_tags'] = df['related_tags'].apply(clean_text)\n",
    "print(df['question_note'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7409e6d9",
   "metadata": {},
   "source": [
    "### Import và chuẩn bị PhoBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1ed121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng labels: 6\n",
      "Labels: ['Xóa đăng ký thường trú' 'Đăng ký thường trú' 'Cấp thẻ thường trú'\n",
      " 'Chuyển đăng ký' 'Điều chỉnh thông tin thường trú' 'Gia hạn']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# Load PhoBERT tokenizer và model\n",
    "model_name = \"vinai/phobert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Số lượng labels (classes)\n",
    "num_labels = len(df_cleaned['Action'].unique())\n",
    "print(f\"Số lượng labels: {num_labels}\")\n",
    "print(f\"Labels: {df_cleaned['Action'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3842808d",
   "metadata": {},
   "source": [
    "### Tạo Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dfea5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length=256):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts.iloc[idx])\n",
    "        label = self.labels.iloc[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd7cd1",
   "metadata": {},
   "source": [
    "### Data Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da1528e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "X = df_cleaned.drop('Action', axis=1)\n",
    "y= df_cleaned['Action']\n",
    "from sklearn.model_selection import train_test_split as train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d0adbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 349\n",
      "Test dataset size: 88\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\minhd\\Documents\\NLP\\data_process.ipynb\n",
    "# Encode labels thành số\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(df_cleaned['Action'])\n",
    "\n",
    "# Chia train/test (sử dụng lại X_train, X_test đã có)\n",
    "y_train_encoded = label_encoder.transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Tạo datasets\n",
    "train_dataset = TextClassificationDataset(\n",
    "    X_train['question_note'], \n",
    "    pd.Series(y_train_encoded), \n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = TextClassificationDataset(\n",
    "    X_test['question_note'], \n",
    "    pd.Series(y_test_encoded), \n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a053b10",
   "metadata": {},
   "source": [
    "### Tạo model và training arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7a8e3ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at vinai/phobert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load PhoBERT model cho classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./phobert_results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d290ce",
   "metadata": {},
   "source": [
    "### 6. Định nghĩa metrics và trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66940b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# Tạo trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658a6acf",
   "metadata": {},
   "source": [
    "### 7. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61944db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [66/66 21:55, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.798600</td>\n",
       "      <td>1.711222</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.392734</td>\n",
       "      <td>0.491093</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.444600</td>\n",
       "      <td>1.240775</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.582424</td>\n",
       "      <td>0.496384</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.128900</td>\n",
       "      <td>0.982175</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.582424</td>\n",
       "      <td>0.496384</td>\n",
       "      <td>0.704545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "eval_loss: 0.9821752905845642\n",
      "eval_accuracy: 0.7045454545454546\n",
      "eval_f1: 0.5824242424242424\n",
      "eval_precision: 0.4963842975206612\n",
      "eval_recall: 0.7045454545454546\n",
      "eval_runtime: 51.7717\n",
      "eval_samples_per_second: 1.7\n",
      "eval_steps_per_second: 0.116\n",
      "epoch: 3.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# filepath: c:\\Users\\minhd\\Documents\\NLP\\data_process.ipynb\n",
    "# Train model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in results.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd5452",
   "metadata": {},
   "source": [
    "8. Prediction and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17508b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                 Chuyển đăng ký       0.00      0.00      0.00         1\n",
      "             Cấp thẻ thường trú       0.00      0.00      0.00         8\n",
      "         Xóa đăng ký thường trú       0.00      0.00      0.00        16\n",
      "Điều chỉnh thông tin thường trú       0.00      0.00      0.00         1\n",
      "             Đăng ký thường trú       0.70      1.00      0.83        62\n",
      "\n",
      "                       accuracy                           0.70        88\n",
      "                      macro avg       0.14      0.20      0.17        88\n",
      "                   weighted avg       0.50      0.70      0.58        88\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\minhd\\anaconda3\\envs\\py311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Predict trên test set\n",
    "predictions = trainer.predict(test_dataset)\n",
    "y_pred = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Decode predictions về tên class\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "# Classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_decoded, y_pred_decoded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
